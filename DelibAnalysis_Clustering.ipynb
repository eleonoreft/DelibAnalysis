{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DelibAnalysis Clustering\n",
    "\n",
    "The following script implements the k-means clustering algorithm in order understand the topics of online comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import sys\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean dataset\n",
    "dataset = data_df = pd.read_csv('combined_scored.csv')\n",
    "labels = dataset.columns\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, max_features=1000, analyzer='word', ngram_range=(3,3))\n",
    "\n",
    "def comment_to_words(raw_comment):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_comment)\n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    return(\" \".join(meaningful_words))\n",
    "\n",
    "clean_train_comments = []\n",
    "\n",
    "dataset[\"cleaned_comment\"] = dataset[\"comment\"].apply(lambda x: comment_to_words(x))\n",
    "\n",
    "fit_vectorizer = vectorizer.fit_transform(dataset['cleaned_comment'])\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "fit_lsa = lsa.fit_transform(fit_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement KMeans\n",
    "\n",
    "km = KMeans(n_clusters=5, init='k-means++', max_iter=100, n_init=10,\n",
    "                verbose=True)\n",
    "km.fit(fit_lsa)\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(fit_lsa, km.labels_, sample_size=1000))\n",
    "\n",
    "\n",
    "print(\"Top terms per cluster:\") \n",
    "\n",
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(5):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print('; %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 15 3-grams by importance\n",
    "idf = vectorizer.idf_\n",
    "idf_dict = dict(zip(vectorizer.get_feature_names(), idf))\n",
    "idf_df = pd.DataFrame.from_dict(idf_dict, orient='index')\n",
    "idf_df = idf_df.sort_values(by=0, ascending=False)\n",
    "for i in range(5):\n",
    "    df = pd.DataFrame(columns = ['ngram', 'tf-idf-score'])\n",
    "    for ind in order_centroids[i, :15]:\n",
    "        df2 = pd.DataFrame([[terms[ind],idf_df.get_value(index=terms[ind], col=0)]], columns = ['ngram', 'tf-idf-score'])\n",
    "        df = df.append(df2)\n",
    "    df = df.sort_values(by='tf-idf-score', ascending=False)\n",
    "    plt = df.plot(kind='barh', legend=None, color='purple')\n",
    "    plt.invert_yaxis()\n",
    "    plt.set_yticklabels(df['ngram'])\n",
    "    plt.set_title(\"Top 15 3-grams by importance: Cluster \" + str(i))\n",
    "    plt.set_xlabel(\"TFIDF Score (importance in dataset)\")\n",
    "    plt.set_ylabel(\"3-grams\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
